\documentclass{article}
\input{../../../style/header.tex}
\begin{document}
\section{Cuerpo}
Es un par $(\K, +, \cdot)$ que cumple
\begin{itemize}
	\item asociatividad y conmutatividad de $+$ y de $\cdot$
	\item distributividad de $\cdot$ sobre $+$
	\item neutro de $+$ (notado $0$) y $\cdot$ (notado $1$)
	\item inverso de $+$ y de $\cdot$ para los distintos de $0$
\end{itemize}

\section{Espacio Vectorial}
Dado un cuerpo $\K$, un espacio vectorial $(\V, +)$ tiene que cumplir
\begin{itemize}
	\item Asociatividad y conmutatividad de $+$ en $\V$
	\item inverso aditivo y neutro en $\V$
	\item $(\lambda\mu)v = \lambda(\mu v)$, con $\lambda, \mu \in \K$, y $v \in \V$
	\item $(\lambda + \mu)v = \lambda v + \mu v$
	\item $\lambda(v + u) = \lambda v + \lambda u$
	\item $1_{\K} \cdot v = v$
\end{itemize}

\section{Matrices en $\K$}
Una matriz de $n \times m$ (primero rows, después columns), es una función
$f : [n] \times [m] \to \K$, o equivalentemente $f \in \K^{n \times m}$

\subsection{Suma de matrices}
Es suma punto a punto

\subsection{Producto de Matrices}
dadas $A \in \K^{n \times m}$ y $B \in \K^{m \times p}$, se define
$C \in \K^{n \times p}, C_{ij} = \sum_{k \leq m} A_{ik} \cdot B_{kj}$

\subsection{Sistema de Ecuaciones}
Si se tiene un sistema de ecuaciones del estilo $\sum_{j \leq m}
\lambda_{ij}x_j = \mu_i$ para $i \leq n$, se dice que se tiene un sistema
de ecuaciones de $n \times m$, ya que si tomamos la matriz $\lambda\in
\K^{n \times m}$ de coeficientes
y la matriz (vector) $\mu \in \K^{n \times 1}$ y la matriz (vector) $x \in
\K ^ {m \times 1}$, el sistema de ecuaciones se reduce a la ecuación:
\[\lambda x = \mu\]
Que representa
\[
	\begin{bmatrix}
		\lambda_{11} & \lambda_{12} & \dots & \lambda_{1m} \\
		\lambda_{21} & \lambda_{12} & \dots & \lambda_{2m} \\
		\vdots & \vdots & \ddots & \vdots \\
		\lambda_{n1} & \lambda_{n2} & \dots & \lambda_{nm} \\
	\end{bmatrix} \times
	\begin{bmatrix}
		x_1 \\
		x_2 \\
		\vdots \\
		x_m
	\end{bmatrix} = 
	\begin{bmatrix}
		\mu_1 \\
		\mu_2 \\
		\vdots \\
		\mu_n
	\end{bmatrix}
\]

\subsection{Sistema Homogéneo}
Cuando se tiene un sistema de ecuaciones con $\mu = 0$, decimos que es homogéneo

\section{Subespacio Vectorial}
Dado $S \in \V$, decimos que es subespacio $\iff$ contiene al $0$, es cerrado bajo
suma y bajo producto por escalar

\subsection{Dadas ecuaciones}
Dado un espacio vectorial $\K^n$ de dimensión $n$,
un subespacio se puede dar como un sistema de ecuaciones homogéneo, es decir,
los subespacios son exactamente los expresables como \[S = \{x \in \K^n
\mid \lambda x = 0\}\]
para alguna matriz $\lambda \in \K ^ {* \times n}$

\subsection{Dados generadores}
El subespacio generado por ciertos vectores $\{v_i\}$, es decir, el conjunto de
combinaciones lineales de todos los $v_i$, se puede expresar como
\[S = \langle \{v_i\} \rangle = \{\lambda x \mid x \in \K ^ {*\times 1}\}
= \lambda \times \K^*\]

Donde $\lambda \in \K ^ {n \times *}= [v_i \mid \dots]$

\subsection{Pasar de Ecuaciones a Generadores}
Usando el método de Gauss, es posible hacer una función $\text{solve} : \K^{*\times n} \to
\K^{n \times *}$ tal que $\{x \mid \lambda x = 0\} = \{(\text{solve} \;\lambda)
x \mid x \in \K^*\}$

El método de Gauss toma una matriz, y aplicando una serie de operaciones que no
alteran las ecuaciones, la pasa a una matriz de forma \emph{row echelon}, es decir
que queda escalonada, y las columnas con leading coefficients son todas 0 excepto
el leading coefficient que es 1), es decir
que queda escalonada, y las columnas con leading coefficients son todas 0 excepto
el leading coefficient que es 1)

Ahí queda que las variables libres son las columnas sin leading coeffcients, y
cada fila no nula representa una variable dependiente, y los coeficientes en
esa fila represenca cuánto de cada variable dependiente hay que poner

\subsection{Generadores a Ecuaciones}
Si tomamos la matriz transpuesta a $A \in \K^{n \times *}$, obtenemos
$A^T$, que si la interpretamos como sist de ecuaciones nos da el subespacio
ortogonal a $\langle A \rangle$

Esto quiere decir que para pasar de generadores a ecuaciones podemos
transponer, pasar de ecuaciones a generadores, y luego transponer de nuevo,
es decir, la función
\[\text{unsolve} : \K^{n\times *} \to \K^{* \times n}, \text{unsolve} =
\text{transpose} \circ \text{solve} \circ \text{transpose}\]

Pasa de generadores a ecuaciones

\section{Intersección de Subespacios}
Es fácil ver que la intersección de dos subespacios es un subespacio

\subsection{Intersección dadas ecuaciones}
Si se tienen dos sistemas de ecuaciones dados por las matrices $A$ y $B$, luego
la intersección está dada por el sistema $
\left[\frac{A}{B}\right]
$

\subsection{Intersección Generador - Ecuación}
Tenemos
\begin{align*}
& \{x \mid Ax = 0\} \cap \{Bx \mid x \in \K^n\} \\
&= \{Bx \mid ABx = 0\} \\
&= B \{x \mid ABx = 0\} \\
&= B \{(\text{solve}\; AB)x \mid x \in \K^n\} \\
&= \{B\times(\text{solve}\; AB)x \mid x \in \K^n\} \\
&= B\times(\text{solve}\; AB) \times \K^*
\end{align*}

Luego la intersección entre el restringido por $A$ y el generado por $B$
es el generado por $B \times (\text{solve}\; AB)$

\subsection{Intersección Generador - Generador}
Conviene pasar uno a ecuaciones y trabajar de ahí

\end{document}
